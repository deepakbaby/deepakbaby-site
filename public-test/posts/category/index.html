<!doctype html><html lang=en><head><title>Top Category Sample</title><style>:root{--bg-primary:#0f172a;--bg-secondary:#1e293b;--bg-card:rgba(255, 255, 255, 0.03);--text-primary:#fff;--text-secondary:#9ca3af;--text-muted:#6b7280;--border-color:rgba(255, 255, 255, 0.08);--orb-opacity:0.5;--toggle-bg:rgba(255, 255, 255, 0.1);--toggle-border:rgba(255, 255, 255, 0.2);--social-bg:rgba(255, 255, 255, 0.05);--social-border:rgba(255, 255, 255, 0.1);--mouse-border:rgba(255, 255, 255, 0.2);--wheel-bg:rgba(255, 255, 255, 0.4);--card-hover-border:rgba(59, 130, 246, 0.3);--card-hover-shadow:rgba(59, 130, 246, 0.15)}[data-theme=light]{--bg-primary:#fafbfc;--bg-secondary:#ffffff;--bg-card:transparent;--text-primary:#1e293b;--text-secondary:#475569;--text-muted:#94a3b8;--border-color:rgba(0, 0, 0, 0.06);--orb-opacity:0.1;--toggle-bg:rgba(0, 0, 0, 0.04);--toggle-border:rgba(0, 0, 0, 0.08);--social-bg:transparent;--social-border:rgba(0, 0, 0, 0.1);--mouse-border:rgba(0, 0, 0, 0.12);--wheel-bg:rgba(0, 0, 0, 0.2);--card-hover-border:rgba(59, 130, 246, 0.3);--card-hover-shadow:rgba(59, 130, 246, 0.08);--card-bg:transparent;--card-border:rgba(0, 0, 0, 0.04);--timeline-color:#3b82f6;--section-bg:#ffffff;--glow-color:rgba(59, 130, 246, 0.08)}body{background-color:var(--bg-primary);color:var(--text-primary)}</style><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/application.c783c6e6b679af484325eb2b13483dfca8aa9b848c0b6e81bd4022ece7a9a0ef.css integrity="sha256-x4PG5rZ5r0hDJesrE0g9/Kiqm4SMC26BvUAi7OepoO8="><link rel=icon type=image/png href=/images/site/favicon_hu_be34366aac4a405.png><link rel=alternate type=application/rss+xml href=https://deepakbaby.in/posts/category/index.xml title="Deepak Baby"><meta property="og:title" content="Deepak Baby"><meta property="og:type" content="website"><meta property="og:description" content="Personal website of Deepak Baby."><meta property="og:image" content="/images/author/deepak.jpeg"><meta property="og:url" content="https://deepakbaby.in"><link rel=stylesheet href=/css/collapsible-sidebars.css><link rel=stylesheet href=/css/comments.css><script integrity="sha256-DO4ugzEwhTW1Id1UIWn0gUJWaebCYOypeTit6LW4QB4=">let theme=localStorage.getItem("theme-scheme")||localStorage.getItem("darkmode:color-scheme")||"light";theme==="system"&&(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?theme="dark":theme="light"),document.documentElement.setAttribute("data-theme",theme)</script></head><body class="type-posts kind-section" data-bs-spy=scroll data-bs-target=#TableOfContents data-bs-offset=80><div class="container-fluid wrapper"><button class=theme-toggle-fixed id=themeToggle aria-label="Toggle theme"><svg class="sun-icon" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><svg class="moon-icon" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg></button><nav class=scroll-navbar id=scrollNavbar><div class=navbar-container><a href=https://deepakbaby.in/ class=navbar-brand><img src=/images/site/favicon.png alt class=navbar-favicon>
Deepak Baby</a><div class=navbar-links><a href=https://deepakbaby.in/#about class=navbar-link>About</a>
<a href=https://deepakbaby.in/#experiences class=navbar-link>Experience</a>
<a href=/posts class=navbar-link>Blog</a>
<a href=https://deepakbaby.in/publications class=navbar-link>Publications</a></div><button class=theme-toggle-navbar id=themeToggleNav aria-label="Toggle theme"><svg class="sun-icon" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364-.707-.707M6.343 6.343l-.707-.707m12.728.0-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><svg class="moon-icon" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003.0 0012 21a9.003 9.003.0 008.354-5.646z"/></svg></button></div></nav><style>.theme-toggle-fixed{position:fixed;top:1.5rem;right:1.5rem;width:44px;height:44px;border-radius:50%;background:var(--toggle-bg,rgba(255,255,255,.1));border:1px solid var(--toggle-border,rgba(255,255,255,.2));display:flex;align-items:center;justify-content:center;cursor:pointer;transition:all .3s;color:var(--text-primary,#fff);z-index:1000}.theme-toggle-fixed:hover{background:var(--toggle-hover-bg,rgba(255,255,255,.2));transform:scale(1.05)}.theme-toggle-fixed svg{width:22px;height:22px}.scroll-navbar.visible~.theme-toggle-fixed,.theme-toggle-fixed.hidden{opacity:0;pointer-events:none}.scroll-navbar.visible~.section-wrapper .theme-toggle-fixed,body:has(.scroll-navbar.visible) .theme-toggle-fixed{opacity:0;pointer-events:none}.scroll-navbar{position:fixed;top:0;left:0;right:0;background:var(--navbar-bg,rgba(15,23,42,.95));backdrop-filter:blur(20px);border-bottom:1px solid var(--border-color,rgba(255,255,255,8%));z-index:999;transform:translateY(-100%);transition:transform .3s ease}.scroll-navbar.visible{transform:translateY(0)}.navbar-container{max-width:1200px;margin:0 auto;padding:1rem 2rem;display:flex;align-items:center;justify-content:space-between}.navbar-brand{display:flex;align-items:center;gap:.75rem;font-family:inter,sans-serif;font-size:1.125rem;font-weight:500;color:var(--text-primary,#fff);text-decoration:none!important;transition:transform .3s ease,color .3s}.navbar-brand:hover,.navbar-brand:focus,.navbar-brand:active{transform:translateY(-2px);color:#3b82f6;text-decoration:none!important}.navbar-favicon{width:28px;height:28px;border-radius:6px}.navbar-links{display:flex;gap:2rem}.navbar-link{font-family:inter,sans-serif;font-size:.875rem;font-weight:400;color:var(--text-secondary,rgba(255,255,255,.7));text-decoration:none!important;transition:transform .3s ease,color .3s;display:inline-block}.navbar-link:hover,.navbar-link:focus,.navbar-link:active{transform:translateY(-2px);color:var(--text-primary,#fff);text-decoration:none!important}.theme-toggle-navbar{width:36px;height:36px;border-radius:50%;background:var(--toggle-bg,rgba(255,255,255,.1));border:1px solid var(--toggle-border,rgba(255,255,255,.2));display:flex;align-items:center;justify-content:center;cursor:pointer;transition:all .3s;color:var(--text-primary,#fff)}.theme-toggle-navbar:hover{background:var(--toggle-hover-bg,rgba(255,255,255,.2))}.theme-toggle-navbar svg{width:18px;height:18px}.sun-icon{display:none}.moon-icon{display:block}[data-theme=light] .sun-icon{display:block}[data-theme=light] .moon-icon{display:none}[data-theme=light] .scroll-navbar{--navbar-bg:rgba(255, 255, 255, 0.98);box-shadow:0 1px 8px rgba(0,0,0,5%);border-bottom-color:transparent}@media(max-width:768px){.theme-toggle-fixed{top:1rem;right:1rem;width:40px;height:40px}.navbar-links{display:none}}</style><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("themeToggle"),a=document.getElementById("themeToggleNav"),t=document.getElementById("scrollNavbar"),n=document.documentElement,r=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: light)").matches?"light":"dark");n.setAttribute("data-theme",r);function s(){const t=n.getAttribute("data-theme"),e=t==="dark"?"light":"dark";n.setAttribute("data-theme",e),localStorage.setItem("theme",e)}e?.addEventListener("click",s),a?.addEventListener("click",s);const o=document.querySelector(".hero-section"),i=o?o.offsetHeight*.6:100;window.addEventListener("scroll",()=>{const n=window.pageYOffset;n>i?(t?.classList.add("visible"),e?.classList.add("hidden")):(t?.classList.remove("visible"),e?.classList.remove("hidden"))}),window.pageYOffset>i&&(t?.classList.add("visible"),e?.classList.add("hidden"))})</script><div class=posts-page-wrapper><section class=search-bar-section><div class=search-bar-container><div class=search-input-wrapper><svg class="search-icon" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5A7 7 0 113 10a7 7 0 0114 0z"/></svg>
<input type=text id=searchInput placeholder="Search posts..." autocomplete=off aria-label="Search posts">
<button class=clear-btn id=clearBtn aria-label="Clear search" style=display:none><svg fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg></button></div><div class=category-filters><button class="filter-pill active" data-category=all>All</button>
<button class=filter-pill data-category="deep learning">deep learning</button>
<button class=filter-pill data-category="distributed training">distributed training</button>
<button class=filter-pill data-category=DDP>DDP</button>
<button class=filter-pill data-category=FSDP>FSDP</button>
<button class=filter-pill data-category="pipeline parallelism">pipeline parallelism</button></div></div></section><section class=posts-grid-section><div class=posts-grid-container><div class=bento-grid><article class="bento-card card-featured" data-tags="deep learning,distributed training,DDP,FSDP,pipeline parallelism,PyTorch,presentation" data-title="Slides: Distributed Training for ML" data-summary="Explore distributed training techniques through this interactive presentation. Navigate through the slides using arrow keys or the navigation controls.
Topics Covered

Back to Basics: Understanding neural network fundamentals
Why Distributed Training: Memory constraints and scaling challenges
DDP (Data Distributed Parallel): Replicating models across GPUs
Pipeline Parallelism: Splitting models across devices
FSDP (Fully Sharded Data Parallel): Advanced sharding techniques

Slides
Use the arrow keys (← →) or click the navigation arrows to move between slides. Some slides include animations that you can step through using the animation controls at the bottom."><a href=/posts/distributed-training-presentation/ class=card-overlay-link aria-label="Read Slides: Distributed Training for ML"></a><div class=card-bg-image><img src=/posts/distributed-training-presentation/presentation-hero.png alt="Slides: Distributed Training for ML" loading=lazy><div class=card-badge>deep learning</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Dec 3, 2025
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
2 min</span></div><h2 class=card-title-text>Slides: Distributed Training for ML</h2><p class=card-description>Explore distributed training techniques through this interactive presentation. Navigate through the slides using arrow keys or the navigation …</p><div class=card-tag-list><span class=card-tag>#deep learning</span>
<span class=card-tag>#distributed training</span>
<span class=card-tag>#DDP</span></div></div></article><article class="bento-card card-medium-tall" data-tags="deep learning,distributed training,DDP,FSDP,pipeline parallelism,PyTorch" data-title="Distributed Training Techniques: DDP, Pipeline Parallelism, and FSDP" data-summary="Modern deep learning models have grown exponentially in size and complexity. GPT-4 has over a trillion parameters, and even &ldquo;smaller&rdquo; models like LLaMA-70B require substantial computational resources. Training or fine-tuning such models on a single GPU is often impossible; not just because of time constraints, but because the model itself may not fit in the memory of a single device. This is where distributed training becomes essential.
Why Do We Need Distributed Training?
The Memory Wall Problem
A modern GPU like the NVIDIA A100 has 80GB of memory. Sounds like a lot? Let&rsquo;s do some math:"><a href=/posts/distributed-training/ class=card-overlay-link aria-label="Read Distributed Training Techniques: DDP, Pipeline Parallelism, and FSDP"></a><div class=card-bg-image><img src=/posts/distributed-training/dt.png alt="Distributed Training Techniques: DDP, Pipeline Parallelism, and FSDP" loading=lazy><div class=card-badge>deep learning</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Dec 1, 2025
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
8 min</span></div><h2 class=card-title-text>Distributed Training Techniques: DDP, Pipeline Parallelism, and FSDP</h2><p class=card-description>Modern deep learning models have grown exponentially in size and complexity. GPT-4 has over a trillion parameters, and even &ldquo;smaller&rdquo; …</p><div class=card-tag-list><span class=card-tag>#deep learning</span>
<span class=card-tag>#distributed training</span>
<span class=card-tag>#DDP</span></div></div></article><article class="bento-card card-medium-wide" data-tags="deep learning,keras,generative models,flow-based models,nice,normalizing flows" data-title="NICE- Non-linear Independent Components Estimation: Insights and Implementation in Keras" data-summary="Keras implementation can be found here.
Flow-based deep generative models have not gained much attention in the research community when compared to GANs or VAEs. This post discusses a flow-based model called NICE, its advantages over the other generative models and finally an implementation in Keras.
While VAEs use an encoder that finds only an approximation of the latent variable corresponding to a datapoint, GANs doesnt even have an encoder to infer latents. In flow-based models, the latent variables can be infered exactly without any approximation. Flow-based models make use of reversible architecture (which will be explained below) which enables accurate inference, in addition to providing optimization over the exact log-likelihood of the data instead of a lower bound of it."><a href=/posts/nice-keras/ class=card-overlay-link aria-label="Read NICE- Non-linear Independent Components Estimation: Insights and Implementation in Keras"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="NICE- Non-linear Independent Components Estimation: Insights and Implementation in Keras" loading=lazy><div class=card-badge>deep learning</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Dec 3, 2019
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
8 min</span></div><h2 class=card-title-text>NICE- Non-linear Independent Components Estimation: Insights and Implementation in Keras</h2><p class=card-description>Keras implementation can be found here.
Flow-based deep generative models have not gained much attention in the research community when compared to …</p><div class=card-tag-list><span class=card-tag>#deep learning</span>
<span class=card-tag>#keras</span>
<span class=card-tag>#generative models</span></div></div></article><article class="bento-card card-medium-tall" data-tags data-title="Implementing Variational Autoencoders: Insights and some tricks" data-summary="This post is a summary of some of the main hurdles I encountered in implementing a VAE on a custom dataset and the tricks I used to solve them. The keras code snippets are also provided. Understanding VAEs and its basic implementation in Keras can be found in the previous post.
Posterior collapse in VAEs
The Goal of VAE is to train a generative model $\mathbb{P}(\mathbf{X}, z)$ to maximize the marginal likelihood $\mathbb{\mathbf{X}}$ of the dataset. The cost function used in training a VAE is comprised of a reconstruction loss and a KL loss as given below."><a href=/posts/vae-insights/ class=card-overlay-link aria-label="Read Implementing Variational Autoencoders: Insights and some tricks"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="Implementing Variational Autoencoders: Insights and some tricks" loading=lazy></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Jul 3, 2019
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
5 min</span></div><h2 class=card-title-text>Implementing Variational Autoencoders: Insights and some tricks</h2><p class=card-description>This post is a summary of some of the main hurdles I encountered in implementing a VAE on a custom dataset and the tricks I used to solve them. The …</p></div></article><article class="bento-card card-small" data-tags="deep learning,vae,variational autoencoder,keras" data-title="Understanding Variational Autoencoders and Implementation in Keras" data-summary="Variational Autoencoders (VAEs)[Kingma, et.al (2013)] let us design complex generative models of data that can be trained on large datasets. This post is about understanding the VAE concepts, its loss functions and how we can implement it in keras.
Generating data from a latent space
VAEs, in terms of probabilistic terms, assume that the data-points in a large dataset are generated from a latent space. For e.g., let us assume we want to generate the image of an animal. First we imagine that it has four legs, a head and a tail. This is analogous to the latent space and from this set of characteristics that are defined in the latent space, the model will learn to generate the image of an animal."><a href=/posts/vae-keras/ class=card-overlay-link aria-label="Read Understanding Variational Autoencoders and Implementation in Keras"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="Understanding Variational Autoencoders and Implementation in Keras" loading=lazy><div class=card-badge>deep learning</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Jul 2, 2019
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
10 min</span></div><h2 class=card-title-text>Understanding Variational Autoencoders and Implementation in Keras</h2><div class=card-tag-list><span class=card-tag>#deep learning</span>
<span class=card-tag>#vae</span>
<span class=card-tag>#variational autoencoder</span></div></div></article><article class="bento-card card-small" data-tags=kaldi,mkl data-title="Installing Kaldi with MKL support without root access" data-summary="Kaldi has recently switched to Intel Math Kernel Libraries (MKL) for linear algebra operations (as of April 2019). However, installing MKL (by running tools/extras/install_mkl.sh) requires root access. This post details how kaldi (with MKL) can be installed without root access.

Download Kaldi
Download the MKL standalone installer from here.

Extract the contents and launch the installer by running install.sh.
When asked for the path to install, specify a location where you have write access (e.g., /home/<username>/intel)
Complete the installation of MKL libraries


Navigate to the kaldi folder kaldi/tools
Typically the first step is to run extras/check_dependencies.sh. This will complain about the missing MKL libraries. This is because the script expects the MKL libraries to be located under /opt/intel directory. As of now (May 2019), there is no option to pass the mkl-root directory to this script. Therefore we will edit the extras/check_dependencies.sh script by changing /opt/intel/mkl/include/mkl.h to /home/<username>/intel/mkl/include/mkl.h. Then running extras/check_dependencies.sh should work fine without any MKL related warnings.
Then run make -j <numcpu> to install the tools required by kaldi
Navigate to the kaldi/src folder.
Run ./configure with the --mkl-root option.
./configure --shared --mkl-root=/home/<username>/intel/mkl

Then install kaldi using the usual steps
make depend -j <numcpu>       
make -j <numcpu>


This will install Kaldi with MKL support without requiring any root privileges."><a href=/posts/kaldi-mkl/ class=card-overlay-link aria-label="Read Installing Kaldi with MKL support without root access"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="Installing Kaldi with MKL support without root access" loading=lazy><div class=card-badge>kaldi</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
May 21, 2019
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
1 min</span></div><h2 class=card-title-text>Installing Kaldi with MKL support without root access</h2><div class=card-tag-list><span class=card-tag>#kaldi</span>
<span class=card-tag>#mkl</span></div></div></article><article class="bento-card card-small" data-tags=kaldi,matlab,python data-title="Training kaldi models with custom features" data-summary="Kaldi Speech Recognition Toolkit is a freely available toolkit that offers several tools for conducting research on automatic speech recognition (ASR). It lets us train an ASR system from scratch all the way from the feature extraction (MFCC,FBANK, ivector, FMLLR,&mldr;), GMM and DNN acoustic model training, to the decoding using advanced language models, and produce state-of-the-art results.
While kaldi offers so much flexibilty at every stage, sometimes we also need to play with features that are not offered by the kaldi repository. Kaldi makes use of ark format to store the features. If we want to perform experiments with customized features, they must be converted to the ark format first. The goal of this post is to explain how we can extract and store the custom features in the ark format using matlab and python."><a href=/posts/kaldi-custom-features/ class=card-overlay-link aria-label="Read Training kaldi models with custom features"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="Training kaldi models with custom features" loading=lazy><div class=card-badge>kaldi</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Mar 6, 2019
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
10 min</span></div><h2 class=card-title-text>Training kaldi models with custom features</h2><div class=card-tag-list><span class=card-tag>#kaldi</span>
<span class=card-tag>#matlab</span>
<span class=card-tag>#python</span></div></div></article><article class="bento-card card-small" data-tags="deep learning,keras" data-title="Tracking Multiple Losses with Keras" data-summary="Often we deal with networks that are optimized for multiple losses (e.g., VAE). In such scenarios, it is useful to keep track of each loss independently, for fine-tuning its contribution to the overall loss. This post details an example on how to do this with keras.
Let us look at an example model which needs to trained to minimize the sum of two losses, say mean square error (MSE) and mean absolute error (MAE). Let $\lambda_{mse}$ be the hyperparameter that controls the contribution of MSE to the toal loss. i.e., the total loss is MAE + $\lambda_{mse}$ * MSE. This loss can be implemented using:"><a href=/posts/keras-multiple-losses/ class=card-overlay-link aria-label="Read Tracking Multiple Losses with Keras"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="Tracking Multiple Losses with Keras" loading=lazy><div class=card-badge>deep learning</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Mar 4, 2019
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
2 min</span></div><h2 class=card-title-text>Tracking Multiple Losses with Keras</h2><div class=card-tag-list><span class=card-tag>#deep learning</span>
<span class=card-tag>#keras</span></div></div></article><article class="bento-card card-small" data-tags=linux,UGent data-title="Tensorflow-GPU in multi-user environment" data-summary="This post is intended for setting up tensorflow-gpu setup in a multi-user setting. This is written as a guide for GPU users at the WAVES research group, Ghent University, Belgium. But these are also applicable to any linux multi-user environment with GPU-based jobs.

Installing Tensorflow in conda

conda installation
conda tensorflow
Testing Tensorflow Installation


Admin only

Installing the cuda compiler and nvidia drivers




Installing Tensorflow in conda
conda installation
Anaconda is a popular python environment among the AI/ML community. The anaconda distribution can be downloaded from here. Follow the instructions here to properly install it to your user account."><a href=/posts/cochlear-ugent/ class=card-overlay-link aria-label="Read Tensorflow-GPU in multi-user environment"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="Tensorflow-GPU in multi-user environment" loading=lazy><div class=card-badge>linux</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Jan 27, 2019
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
5 min</span></div><h2 class=card-title-text>Tensorflow-GPU in multi-user environment</h2><div class=card-tag-list><span class=card-tag>#linux</span>
<span class=card-tag>#UGent</span></div></div></article><article class="bento-card card-small" data-tags=ai,malayalam data-title="Google Duplex" data-summary="ഒരു കമ്പ്യൂട്ടർ നിങ്ങൾക്കുവേണ്ടി ഒരു ബാർബർ ഷോപ്പിലേക്കോ ഹോട്ടലിലേക്കോ ഫോൺ ചെയ്തു റിസർവേഷൻ എടുത്തുതരുന്ന കാലത്തെപ്പറ്റി നിങ്ങൾ ചിന്തിച്ചിട്ടുണ്ടോ? എങ്കിൽ അറിയുക, നാം അവിടെയെത്തിയെന്ന്! അതാണ് ഗൂഗിൾ ഡ്യൂപ്ളെക്സ് (Google Duplex) .

ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ് ഭാഗം- 5
AI രംഗത്തെ ഏറ്റവും പ്രധാനപ്പെട്ട നാഴികക്കല്ലുകളിലൊന്നിനാണ് നമ്മൾ ഇന്നലെ സാക്ഷ്യം വഹിച്ചത്. നമുക്കുവേണ്ടി ഫോൺ കാളുകൾ നടത്താനും അവിടെയുള്ളവരോട് സംസാരിക്കാനും കഴിയുന്ന AI സംവിധാനമായ Google Duplex ഇന്നലെ ഗൂഗിൾ അവതരിപ്പിച്ചു (വീഡിയോ കാണുക). Google assistant കുറെ കാലമായി നമ്മൾ കണ്ടിരുന്നതാണെങ്കിലും അതിനു ധാരാളം പരിമിതികളുണ്ടായിരുന്നു. അതിൽനിന്നൊക്കെ വളരെയധികം മുന്നോട്ടുപോയ ഒരു മനുഷ്യൻതന്നെയെന്നു തോന്നിപ്പിക്കുമാറ് നമ്മുടെ സംസാരത്തിലെ ചെറിയ കാര്യങ്ങൾ വരെ (ഇടക്കുള്ള pause, hmmm, err ശബ്ദങ്ങൾ) ഉൾപ്പെടുത്തിയാണ് ഈ AI സംവിധാനം സംസാരിക്കുന്നത്!"><a href=/posts/ai-5/ class=card-overlay-link aria-label="Read Google Duplex"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="Google Duplex" loading=lazy><div class=card-badge>ai</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
May 9, 2018
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
3 min</span></div><h2 class=card-title-text>Google Duplex</h2><div class=card-tag-list><span class=card-tag>#ai</span>
<span class=card-tag>#malayalam</span></div></div></article><article class="bento-card card-small" data-tags=ai,malayalam data-title="ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 4 " data-summary="ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് ഗവേഷണത്തിൽ ഇന്ന് ഏറ്റവുമധികം ഉപയോഗത്തിലിരിക്കുന്ന ന്യൂറൽ നെറ്റ്‌വർക്കുകളെ കുറിച്ചാണ് കഴിഞ്ഞ ഭാഗത്തിൽ പറഞ്ഞത് (കഴിഞ്ഞ ഭാഗം ഇവിടെ വായിക്കാം). ഇനി ചരിത്രത്തിലെ രണ്ടാം ഘട്ടത്തിലേക്ക്. മുമ്പുപറഞ്ഞതുപോലെ ന്യൂറൽ നെറ്റ്‌വർക്കുമായി ബന്ധപ്പെട്ട ആദ്യകാല ശ്രമങ്ങളും ഗവേഷണങ്ങളുമാണ് ഈ ഭാഗത്തിൽ.
1943 - ഇലെക്ട്രിക്കൽ സർക്യൂട്ടുകൾ ഉപയോഗിച്ച് ഒരു ന്യൂറൽ നെറ്റ്‌വർക്ക് നിർമ്മിക്കപ്പെട്ടു
നമ്മുടെ ന്യൂറോണുകൾ എങ്ങനെയായിരിക്കും പ്രവർത്തിക്കുന്നത് എന്നതിനെപ്പറ്റി ന്യൂറോഫൈസിയോളജിസ്റ്റായ വാറൻ മക്കുല്ലോഷും ഗണിതജ്ഞനായ വാൾട്ടർ പിട്സും ചേർന്ന് ഒരു സിദ്ധാന്തം അവതരിപ്പിച്ചു. അതിന്റെ ഒരു ചെറിയ മോഡൽ ഇലെക്ട്രിക്കൽ സർക്യൂട്ടുകൾ ഉപയോഗിച്ച് അവർ നിർമിക്കുകയും ചെയ്തു. നമ്മുടെ ശരീരത്തിലെ ന്യൂറോണുകളുടെ പ്രവർത്തനത്തെപ്പറ്റി അനുലഭ്യമായിരുന്ന പരിമിതമായ അറിവുവച്ചാണ് അത്തരമൊരു മാതൃക അവർ നിർമ്മിച്ചത്.
1952- checkers game കളിക്കുന്ന കമ്പ്യൂട്ടർ"><a href=/posts/ai-4/ class=card-overlay-link aria-label="Read ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 4 "></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 4 " loading=lazy><div class=card-badge>ai</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Apr 24, 2018
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
3 min</span></div><h2 class=card-title-text>ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 4</h2><div class=card-tag-list><span class=card-tag>#ai</span>
<span class=card-tag>#malayalam</span></div></div></article><article class="bento-card card-small" data-tags=ai,malayalam data-title="ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 3" data-summary="ന്യൂറൽ നെറ്റ്‌വർക്കുകൾ 
1950 കൾക്ക് മുൻപുള്ള, ഇന്നത്തെ കമ്പ്യൂട്ടർ സയൻസിന്റെയും ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസിന്റെയും വളർച്ചക്ക് വിത്തുപാകിയ ചില സിദ്ധാന്തങ്ങളാണ് കഴിഞ്ഞ ഭാഗത്തിൽ പറഞ്ഞത്. അത്തരം സിദ്ധാന്തങ്ങളിൽ നിന്നും പ്രചോദനമുൾക്കൊണ്ട് പ്രവർത്തിക്കുന്ന യന്ത്രങ്ങൾ 1950 കൾക്ക് ശേഷമാണ് യാഥാർഥ്യമായത്. അന്നുമുതൽ 2006 വരെയുള്ള കാലമാണ് AI ചരിത്രത്തിലെ രണ്ടാം ഘട്ടം. അതിലേക്കു കടക്കുന്നതിനുമുന്പ് നമ്മൾ ന്യൂറൽ നെറ്റ്‌വർക്ക് എന്താണെന്ന് മനസിലാക്കേണ്ടതുണ്ട്.
കൃത്രിമബുദ്ധി അഥവാ AI എന്നത് മഷിനുകൾക്കു മനുഷ്യനെപ്പോലെ ചിന്തിക്കാനുള്ള ബുദ്ധി കൃത്രിമമായി നിർമിക്കുന്ന പ്രക്രിയയാണ്. നമ്മുടെ തലച്ചോറിനെയും, അതിലേക്കു ബന്ധപ്പെട്ടിരിക്കുന്ന, നമ്മുടെ ഇന്ദ്രിയങ്ങളിൽനിന്നും സിഗ്നലുകൾ അവിടേക്കെത്തിക്കുന്ന ന്യൂറോണുകളെയും അടിസ്ഥാനപ്പെട്ടാണ് നമ്മുടെ ബുദ്ധി ഇരിക്കുന്നത്. നമ്മുടെ തലച്ചോറിൽ 100 ബില്യണിലധികം ന്യൂറോണുകൾ ഉണ്ടെന്നാണ് കണക്ക്. നമ്മുടെ ഇന്ദ്രിയങ്ങളിൽ നിന്നും വരുന്ന ഇത്തരം കോടിക്കണക്കിനു സിഗ്നലുകളെ ക്രോഡീകരിച്ചാണ് നമ്മുടെ തലച്ചോറ് സംവേദനം (പെർസെപ്ഷൻ) എന്നത് സാധ്യമാക്കുന്നത്. ഉദാഹരണം പറഞ്ഞാൽ, നാം ഒരാളെ കാണുമ്പോൾ അയാളിൽനിന്നും വരുന്ന പ്രകാശകിരണങ്ങൾ നമ്മുടെ കണ്ണിൽ പതിക്കുകയും ആ കിരണങ്ങൾക്കനുസൃതമായി കണ്ണിൽ നിന്നും സിഗ്നലുകൾ തലച്ചോറിലേക്ക് ന്യൂറോണുകൾ എത്തിക്കുകയും ചെയ്യും. ഈ സിഗ്നലുകളിൽ നിന്നാണ് നമ്മുടെ തലച്ചോറ് നാം ആ ആളെ കണ്ടു എന്ന തോന്നൽ അല്ലെങ്കിൽ perception ഉണ്ടാക്കുന്നത്. കാഴ്ചക്ക് തലച്ചോറിലെ visual cortex എന്ന ഭാഗമാണ് പ്രധാനമായും ഉപയോഗിക്കുന്നത്. നമ്മുടെ തലച്ചോറ് ന്യൂറോണുകളിൽനിന്നും വരുന്ന സിഗ്നലുകളെ എങ്ങനെ ക്രോഡീകരിക്കുന്നു എന്നത് ഇന്നും നമുക്കധികം മനസിലാകാത്ത വിഷയമാണ്. അത് അറിയില്ലാത്തതുകൊണ്ടാണ് AI തീരുമാനങ്ങൾ (decision making ) എടുക്കാൻ മറ്റു സങ്കേതങ്ങൾ ഉപയോഗിക്കുന്നതും. (മറ്റു സങ്കേതങ്ങളെ പറ്റി വരും ഭാഗങ്ങളിൽ പറയാം)"><a href=/posts/ai-3/ class=card-overlay-link aria-label="Read ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 3"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 3" loading=lazy><div class=card-badge>ai</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Apr 16, 2018
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
3 min</span></div><h2 class=card-title-text>ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 3</h2><div class=card-tag-list><span class=card-tag>#ai</span>
<span class=card-tag>#malayalam</span></div></div></article><article class="bento-card card-small" data-tags=ai,malayalam data-title="ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 2" data-summary="യന്ത്രങ്ങൾ കണ്ടുപിടിച്ച കാലം മുതൽക്കേ മനുഷ്യനെ ത്രസിപ്പിച്ചിരുന്ന ആശയമായിരുന്നു സ്വയബുദ്ധിയോടെ പ്രവർത്തിക്കുന്ന യന്ത്രങ്ങൾ. കുറെ യന്ത്രഭാഗങ്ങളുടെ ചലനത്തെമാത്രം അടിസ്ഥാനമാക്കി പ്രവർത്തിച്ചിരുന്ന യന്ത്രങ്ങളിൽ നിന്ന് ഇന്നു നമ്മുടെ സാങ്കേതികവിദ്യ വളരെയേറെ മുന്നോട്ടുപോയിരിക്കുന്നു. ആ വഴിയിലെ ചില പ്രധാനപ്പെട്ട കണ്ടുപിടുത്തങ്ങളാണ് ഈ ഭാഗത്തിൽ.
ഈ ചരിത്രത്തെ മൂന്ന് ഘട്ടങ്ങളായി തിരിക്കാം. കംപ്യൂട്ടർ എന്ന മെഷിൻ നിര്മിക്കപ്പെടുന്നതിനുമുമ്പ് ഇങ്ങനെയൊരു മഷിന്റെ സാധ്യതകളെക്കുറിച്ചു ചില സിദ്ധാന്തങ്ങൾ അവതരിപ്പിക്കപ്പെട്ടു. ഇന്നത്തെ കംപ്യൂട്ടറുകൾ പലതും അത്തരം സിദ്ധാന്തങ്ങൾ അടിസ്ഥാനമാക്കി നിർമിക്കപ്പെട്ടവയാണ്. 1950 നു മുൻപുള്ള ആ കാലഘട്ടത്തിലെ പ്രധാന നാഴികക്കല്ലുകളാണ് ഈ ഭാഗത്തിൽ. സിദ്ധാന്തങ്ങളിൽ നിന്നും കമ്പ്യൂട്ടർ എന്ന മെഷിൻ എങ്ങനെയാണ് യാഥാർഥ്യമായതു എന്നതും അതിനോടൊപ്പം മെഷീൻ ലേർണിംഗ്/ കൃത്രിമബുദ്ധി ഉണ്ടാക്കാനുള്ള ശ്രമങ്ങളുമാണ് രണ്ടാം ഭാഗം. അത് 1980 കളോടെ അവസാനിക്കും. പിന്നീട് AI ഗവേഷണം ഉയർത്തെഴുന്നേൽക്കുന്നത് 2006 ലാണ്. അന്നുതൊട്ടുള്ള ചെറുചരിത്രവും അതിനു ചുക്കാൻപിടിച്ച ഇന്നത്തെ പ്രമുഖരായ ഗവേഷകരെപ്പറ്റിയുമായിരിക്കും മൂന്നാം ഭാഗം. "><a href=/posts/ai-2/ class=card-overlay-link aria-label="Read ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 2"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 2" loading=lazy><div class=card-badge>ai</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Apr 8, 2018
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
4 min</span></div><h2 class=card-title-text>ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 2</h2><div class=card-tag-list><span class=card-tag>#ai</span>
<span class=card-tag>#malayalam</span></div></div></article><article class="bento-card card-small" data-tags=ai,malayalam data-title="മെഷീൻ ലേണിങ്/ ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്" data-summary="
കേംബ്രിഡ്ജ് അനാലിറ്റിക്കയും അതുവഴി ഫേസ്ബുക് പിടിച്ച പുലിവാലുമൊക്കെ എല്ലാവരും അറിഞ്ഞിരിക്കുമല്ലോ. ഉപയോക്താക്കളുടെ വിവരങ്ങൾ ചോർത്തി, ആ വിവരങ്ങൾ ഉപയോഗിച്ച് നമ്മുടെ ചിന്തകളെ സ്വാധീനിക്കുന്ന തരം പോസ്റ്റുകൾ നമ്മുടെ ന്യൂസ് ഫീഡിലേക്ക് കടത്തിവിടുകയാണ് കേംബ്രിഡ്ജ് അനാലിറ്റിക്ക ചെയ്തതെന്നും പലരും വായിച്ചിരിക്കും. എന്നാൽ എങ്ങനെയാണ് ഒരാളുടെ വിവരങ്ങളിൽ നിന്നും ഇതെല്ലാം മനസിലാക്കി, എന്തുതരം പോസ്റ്റുകൾ ഇടണം എന്ന തീരുമാനം എടുക്കുന്നതെന്നു പലർക്കും മനസിലായിട്ടുണ്ടാവില്ല. ഇത്രയധികം ഉപയോക്താക്കളുടെ ഡാറ്റ പരിശോധിച്ച് അവരുടെ അഭിരുചികൾ മനസിലാക്കി കൃത്യമായ പോസ്റ്റുകൾ കടത്തിവിടാൻ ഒരു മനുഷ്യനെക്കൊണ്ടു സാധിക്കില്ലെന്നുറപ്പ്. അപ്പോൾ പിന്നെ അത് കമ്പ്യൂട്ടർ തന്നെ.
എന്നാലും കമ്പ്യൂട്ടർ ഒരു മെഷിനല്ലേ. അതിനു ഇത്തരത്തിലൊരു കഴിവുണ്ടോ ? കംപ്യൂട്ടറുകൾ സത്യത്തിൽ വെറും മണ്ടന്മാരാണ്. അതിനു ആകെക്കൂടെ കുറെ സംഖ്യകളെ കൂട്ടാനും കുറക്കാനും ഗുണിക്കാനും ഹരിക്കാനും അറിയാം.. നമ്മൾ മനുഷ്യരെപോലെ പഞ്ചേന്ദ്രിയങ്ങളോ അവയിൽനിന്നു വരുന്ന വിവരങ്ങളെ ഏകോപിപ്പിക്കുന്ന ഒരു തലച്ചോറോ ഇല്ല. നമ്മുടെ വിവരങ്ങളെല്ലാം കമ്പ്യൂട്ടറുകൾ കാണുന്നത് സംഖ്യകൾ ആയിട്ടാണ്. എല്ലാവര്ക്കും ബൈനറി നമ്പർ സിസ്റ്റം അറിയാമെന്നു കരുതുന്നു. കമ്പ്യൂട്ടറിൽ എല്ലാം 1 അല്ലെങ്കിൽ 0 ആയിട്ടാണ് എല്ലാം ശേഖരിച്ചുവച്ചിരിക്കുന്നത്. ഇങ്ങനെയുള്ള കുറെ ഒന്നുകളിൽ നിന്നും പൂജ്യങ്ങളിൽ നിന്നും കമ്പ്യൂട്ടറിനെ ഒരു തീരുമാനം എടുക്കാൻ പഠിപ്പിക്കുന്ന ശാസ്ത്രശാഖയാണ് ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് അഥവാ മെഷീൻ ലേർണിംഗ്."><a href=/posts/ai-1/ class=card-overlay-link aria-label="Read മെഷീൻ ലേണിങ്/ ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="മെഷീൻ ലേണിങ്/ ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്" loading=lazy><div class=card-badge>ai</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Apr 1, 2018
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
3 min</span></div><h2 class=card-title-text>മെഷീൻ ലേണിങ്/ ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്</h2><div class=card-tag-list><span class=card-tag>#ai</span>
<span class=card-tag>#malayalam</span></div></div></article><article class="bento-card card-small" data-tags=linux,UGent data-title="A quick start guide for Linux users at Intec" data-summary="
What does this guide offer?
Software packages and OS

Install a linux OS
Openvpn
Matlab


Miscellaneous

Configuring printer
Before using apollo webpage
Mounting Intec file share




What does this guide offer?
This report aims as a quick guide for setting up linux machines in Intec, UGent. It may not contain help on everything, but the goal is to keep adding things as we encounter and solve them. The instructions are for fedora 25, unless otherwise mentioned. For other linux distributions, you might need to appropriately change the command-line instructions."><a href=/posts/ugent-linux/ class=card-overlay-link aria-label="Read A quick start guide for Linux users at Intec"></a><div class=card-bg-image><img src=/images/default-hero.jpg alt="A quick start guide for Linux users at Intec" loading=lazy><div class=card-badge>linux</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Jun 6, 2017
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
6 min</span></div><h2 class=card-title-text>A quick start guide for Linux users at Intec</h2><div class=card-tag-list><span class=card-tag>#linux</span>
<span class=card-tag>#UGent</span></div></div></article><article class="bento-card card-small" data-tags=Basic,Multi-lingual data-title=Introduction data-summary="Greeting! This is an introduction post. This post tests the followings:

Hero image is in the same directory as the post.
This post should be at top of the sidebar.
Post author should be the same as specified in author.yaml file.
"><a href=/posts/introduction/ class=card-overlay-link aria-label="Read Introduction"></a><div class=card-bg-image><img src=/posts/introduction/hero.svg alt=Introduction loading=lazy><div class=card-badge>Basic</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Jun 8, 2000
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
1 min</span></div><h2 class=card-title-text>Introduction</h2><div class=card-tag-list><span class=card-tag>#Basic</span>
<span class=card-tag>#Multi-lingual</span></div></div></article><article class="bento-card card-small" data-tags data-title="Markdown Samples" data-summary="This is a sample post intended to test the followings:

A different post author.
Table of contents.
Markdown content rendering.
Math rendering.
Emoji rendering.


Markdown Syntax Rendering
Headings
The following HTML <h1>—<h6> elements represent six levels of section headings. <h1> is the highest section level while <h6> is the lowest.
H1
H2
H3
H4
H5
H6
Paragraph
Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat."><a href=/posts/markdown-sample/ class=card-overlay-link aria-label="Read Markdown Samples"></a><div class=card-bg-image><img src=/posts/markdown-sample/hero.svg alt="Markdown Samples" loading=lazy></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Jun 8, 2000
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
3 min</span></div><h2 class=card-title-text>Markdown Samples</h2></div></article><article class="bento-card card-small" data-tags="Markdown,Content Organization,Multi-lingual" data-title="Rich Content" data-summary="This sample post tests the followings:

Category, sub-category nesting in the sidebar.
Hero image and other images are in images folder inside this post directory.
Different media rendering like image, tweet, YouTube video, Vimeo video etc.

Image Sample



Tweet Sample
Owl bet you'll lose this staring contest 🦉 pic.twitter.com/eJh4f2zncC&mdash; San Diego Zoo Wildlife Alliance (@sandiegozoo) October 26, 2021




YouTube Video Sample

      
    


Vimeo Video Sample

      
        
        
      "><a href=/posts/category/sub-category/rich-content/ class=card-overlay-link aria-label="Read Rich Content"></a><div class=card-bg-image><img src=/posts/category/sub-category/rich-content/images/forest.jpg alt="Rich Content" loading=lazy><div class=card-badge>Markdown</div></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Jun 8, 2000
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
1 min</span></div><h2 class=card-title-text>Rich Content</h2><div class=card-tag-list><span class=card-tag>#Markdown</span>
<span class=card-tag>#Content Organization</span>
<span class=card-tag>#Multi-lingual</span></div></div></article><article class="bento-card card-small" data-tags data-title="Shortcodes Samples" data-summary='This is a sample post intended to test the followings:

Default hero image.
Different shortcodes.

Alert
The following alerts are available in this theme.



    



    
    This is sample alert with type="success".





    



    
    This is sample alert with type="danger".





    



    
    This is sample alert with type="warning".





    



    
    This is sample alert with type="info".







    
    This is sample alert with type="dark".







    
    This is sample alert with type="primary".







    
    This is sample alert with type="secondary".


Image
A sample image without any attribute.



A sample image with height and width attributes.



A center aligned image with height and width attributes.



A image with float attribute.


Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras egestas lectus sed leo ultricies ultricies. Praesent tellus risus, eleifend vel efficitur ac, venenatis sit amet sem. Ut ut egestas erat. Fusce ut leo turpis. Morbi consectetur sed lacus vitae vehicula. Cras gravida turpis id eleifend volutpat. Suspendisse nec ipsum eu erat finibus dictum. Morbi volutpat nulla purus, vel maximus ex molestie id. Nullam posuere est urna, at fringilla eros venenatis quis.'><a href=/posts/shortcodes/ class=card-overlay-link aria-label="Read Shortcodes Samples"></a><div class=card-bg-image><img src=/posts/shortcodes/boat.jpg alt="Shortcodes Samples" loading=lazy></div><div class=card-content-wrapper><div class=card-meta-info><span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5A2 2 0 003 7v12a2 2 0 002 2z"/></svg>
Jun 8, 2000
</span><span class=meta-divider>•</span>
<span class=meta-item><svg width="14" height="14" fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3A9 9 0 113 12a9 9 0 0118 0z"/></svg>
3 min</span></div><h2 class=card-title-text>Shortcodes Samples</h2></div></article></div><div class=no-results-message id=noResults style=display:none><svg fill="none" stroke="currentcolor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.172 16.172a4 4 0 015.656.0M9 10h.01M15 10h.01M21 12A9 9 0 113 12a9 9 0 0118 0z"/></svg><h3>No posts found</h3><p>Try adjusting your search or category filter</p></div></div></section></div><style>@import 'https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap';body.type-posts,body.type-posts *{box-sizing:border-box}.type-posts .container-fluid.wrapper,.type-posts .wrapper,.type-posts .content-section,.type-posts .page-content{max-width:none!important;width:100%!important;padding:0!important;margin:0!important}.type-posts .wrapper .sidebar-section,.type-posts .toc-section{display:none!important}.posts-page-wrapper{width:100vw!important;max-width:100vw!important;margin:0!important;padding:0!important;overflow-x:hidden!important;font-family:inter,-apple-system,BlinkMacSystemFont,sans-serif;background:var(--bg-primary);color:var(--text-primary);min-height:100vh;padding-top:5rem}.search-bar-section{position:sticky;top:5rem;z-index:99;background:rgba(15,23,42,.95);backdrop-filter:blur(20px);border-bottom:1px solid rgba(255,255,255,8%);padding:1.5rem 2rem}[data-theme=light] .search-bar-section{background:rgba(250,251,252,.95);border-bottom-color:rgba(0,0,0,6%)}.search-bar-container{max-width:1400px;margin:0 auto;display:flex;flex-direction:column;gap:1rem;align-items:center}.search-input-wrapper{position:relative;width:100%;max-width:600px}.search-icon{position:absolute;left:1.25rem;top:50%;transform:translateY(-50%);width:18px;height:18px;color:var(--text-muted);pointer-events:none;z-index:2}#searchInput{width:100%;height:48px;padding:0 3.5rem;background:rgba(255,255,255,5%);border:1px solid rgba(255,255,255,.1);border-radius:50px;color:var(--text-primary);font-size:.95rem;font-family:inter,sans-serif;transition:all .3s ease}[data-theme=light] #searchInput{background:rgba(255,255,255,.8);border-color:rgba(0,0,0,.1)}#searchInput:focus{outline:none;border-color:rgba(59,130,246,.5);box-shadow:0 0 0 3px rgba(59,130,246,.1);background:rgba(255,255,255,8%)}#searchInput::placeholder{color:var(--text-muted)}.clear-btn{position:absolute;right:1.25rem;top:50%;transform:translateY(-50%);width:24px;height:24px;padding:0;background:rgba(255,255,255,.1);border:none;border-radius:50%;color:var(--text-secondary);cursor:pointer;transition:all .2s;display:flex;align-items:center;justify-content:center;z-index:2}.clear-btn svg{width:12px;height:12px}.clear-btn:hover{background:rgba(255,255,255,.2)}.category-filters{display:flex;gap:.625rem;flex-wrap:wrap;justify-content:center}.filter-pill{padding:.5rem 1rem;background:rgba(255,255,255,5%);border:1px solid rgba(255,255,255,.1);border-radius:50px;color:var(--text-secondary);font-size:.85rem;font-weight:500;font-family:inter,sans-serif;cursor:pointer;transition:all .3s;text-transform:capitalize}.filter-pill:hover{border-color:rgba(59,130,246,.5);color:#3b82f6;transform:translateY(-2px)}.filter-pill.active{background:#3b82f6;border-color:#3b82f6;color:#fff;box-shadow:0 4px 12px rgba(59,130,246,.3)}.posts-grid-section{padding:4rem 2rem;background:var(--bg-primary)}.posts-grid-container{max-width:1400px;margin:0 auto}.bento-grid{display:grid;grid-template-columns:repeat(4,1fr);gap:1.5rem;grid-auto-flow:dense}.card-featured{grid-column:span 2;grid-row:span 2}.card-medium-wide{grid-column:span 2;grid-row:span 1}.card-medium-tall{grid-column:span 1;grid-row:span 2}.card-small{grid-column:span 1;grid-row:span 1}.bento-card{position:relative;background:rgba(255,255,255,3%);border:1px solid rgba(255,255,255,.15);border-radius:16px;overflow:hidden;transition:all .4s cubic-bezier(.23,1,.32,1);display:flex;flex-direction:column;opacity:0;transform:scale(.95);animation:cardFadeIn .6s ease-out forwards;min-height:400px;box-shadow:0 4px 12px rgba(0,0,0,.3),0 2px 6px rgba(0,0,0,.2)}.card-featured{min-height:550px}.card-medium-wide{min-height:380px}.card-medium-tall{min-height:500px}.card-small{min-height:400px}@keyframes cardFadeIn{to{opacity:1;transform:scale(1)}}.bento-card:nth-child(1){animation-delay:0ms}.bento-card:nth-child(2){animation-delay:80ms}.bento-card:nth-child(3){animation-delay:160ms}.bento-card:nth-child(4){animation-delay:240ms}.bento-card:nth-child(5){animation-delay:320ms}.bento-card:nth-child(6){animation-delay:400ms}.bento-card:nth-child(7){animation-delay:480ms}.bento-card:nth-child(8){animation-delay:560ms}.bento-card:nth-child(n+9){animation-delay:640ms}.bento-card.hidden{display:none}@media(hover:hover) and (min-width:1200px){.bento-card{transform-style:preserve-3d}.bento-card:hover{border-color:rgba(59,130,246,.3);box-shadow:0 30px 80px rgba(59,130,246,.25);transform:perspective(1000px)rotateX(var(--rotate-x,0deg))rotateY(var(--rotate-y,0deg))translateZ(10px)}}@media(hover:hover) and (max-width:1199px){.bento-card:hover{border-color:rgba(59,130,246,.3);box-shadow:0 20px 50px rgba(59,130,246,.2);transform:translateY(-4px)}}.card-overlay-link{position:absolute;inset:0;z-index:10}.card-bg-image{position:relative;width:100%;flex-shrink:0;overflow:hidden;background:var(--bg-secondary)}.card-featured .card-bg-image{height:350px}.card-medium-wide .card-bg-image{height:220px}.card-medium-tall .card-bg-image{height:280px}.card-small .card-bg-image{height:220px}.card-bg-image img{width:100%;height:100%;object-fit:cover;transition:transform .6s cubic-bezier(.23,1,.32,1)}.bento-card:hover .card-bg-image img{transform:scale(1.08)}.card-placeholder{width:100%;height:100%;display:flex;align-items:center;justify-content:center;background:linear-gradient(135deg,rgba(59,130,246,.1),rgba(139,92,246,.1));color:rgba(255,255,255,.2)}.card-badge{position:absolute;top:1rem;right:1rem;padding:.375rem .875rem;background:rgba(0,0,0,.6);backdrop-filter:blur(10px);border-radius:50px;color:#fff;font-size:.7rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;z-index:2}[data-theme=light] .card-badge{background:rgba(255,255,255,.9);color:#1e293b}.card-content-wrapper{position:relative;z-index:2;padding:1.5rem;display:flex;flex-direction:column;gap:.75rem;flex-grow:1;background:rgba(255,255,255,3%)}[data-theme=light] .card-content-wrapper{background:rgba(255,255,255,.8)}.card-featured .card-content-wrapper{padding:2rem}.card-meta-info{display:flex;align-items:center;gap:.625rem;font-size:.8rem;color:rgba(255,255,255,.7)}.card-meta-info svg{width:13px;height:13px;margin-right:.25rem}.meta-item{display:flex;align-items:center}.meta-divider{opacity:.5}[data-theme=light] .card-meta-info{color:rgba(0,0,0,.6)}.card-title-text{font-size:1.125rem;font-weight:400;color:#fff;margin:0;line-height:1.3;letter-spacing:-.01em;display:-webkit-box;-webkit-line-clamp:2;line-clamp:2;-webkit-box-orient:vertical;overflow:hidden}[data-theme=light] .card-title-text{color:#1e293b}.card-featured .card-title-text{font-size:clamp(1.5rem,2.5vw,2rem);font-weight:400;-webkit-line-clamp:3;line-clamp:3}.card-medium-wide .card-title-text,.card-medium-tall .card-title-text{font-size:1.25rem;font-weight:400}.card-description{font-size:.95rem;line-height:1.6;color:rgba(255,255,255,.65);margin:0;display:-webkit-box;-webkit-line-clamp:3;line-clamp:3;-webkit-box-orient:vertical;overflow:hidden}[data-theme=light] .card-description{color:#64748b}.card-featured .card-description{font-size:1rem;-webkit-line-clamp:4;line-clamp:4}.card-tag-list{display:flex;flex-wrap:wrap;gap:.5rem}.card-tag{padding:.25rem .625rem;background:rgba(59,130,246,.15);border:1px solid rgba(59,130,246,.25);border-radius:50px;color:#60a5fa;font-size:.7rem;font-weight:500}.no-results-message{text-align:center;padding:5rem 2rem;color:var(--text-secondary)}.no-results-message svg{width:80px;height:80px;margin-bottom:1.5rem;color:var(--text-muted)}.no-results-message h3{font-size:1.5rem;color:var(--text-primary);margin-bottom:.5rem}[data-theme=light] .bento-card{background:rgba(255,255,255,.95);border:1px solid rgba(0,0,0,.12);box-shadow:0 2px 8px rgba(0,0,0,8%),0 1px 3px rgba(0,0,0,6%)}[data-theme=light] .bento-card:hover{border-color:rgba(59,130,246,.4);box-shadow:0 8px 24px rgba(0,0,0,.12),0 4px 12px rgba(59,130,246,.15)}@media(max-width:1199px){.bento-grid{grid-template-columns:repeat(2,1fr);gap:1.25rem}.card-featured{grid-column:span 2;grid-row:span 1}.card-medium-wide{grid-column:span 2;grid-row:span 1}.card-medium-tall{grid-column:span 1;grid-row:span 1}.card-small{grid-column:span 1;grid-row:span 1}}@media(max-width:767px){.posts-page-wrapper{padding-top:4rem}.search-bar-section{top:4rem;padding:1.25rem 1.5rem}.search-input-wrapper{max-width:100%}.category-filters{overflow-x:auto;flex-wrap:nowrap;justify-content:flex-start;width:100%;padding-bottom:.5rem;-webkit-overflow-scrolling:touch}.posts-grid-section{padding:3rem 1.5rem}.bento-grid{grid-template-columns:1fr;gap:1.25rem}.card-featured,.card-medium-wide,.card-medium-tall,.card-small{grid-column:span 1;grid-row:span 1;min-height:380px}.card-featured{min-height:450px}.card-featured .card-bg-image{height:250px}.card-medium-wide .card-bg-image,.card-medium-tall .card-bg-image,.card-small .card-bg-image{height:200px}.card-title-text{font-size:1.05rem}.card-featured .card-title-text{font-size:1.35rem}.card-content-wrapper,.card-featured .card-content-wrapper{padding:1.25rem}.card-description{font-size:.9rem}}@media(prefers-reduced-motion:reduce){.bento-card,.card-bg-image img,#searchInput,.filter-pill{animation:none;transition:none}.bento-card{opacity:1;transform:none}}</style><script>(function(){"use strict";function s(e,t){let n;return function(...s){const o=()=>{clearTimeout(n),e(...s)};clearTimeout(n),n=setTimeout(o,t)}}function e(){if(window.innerWidth<1200||!window.matchMedia("(hover: hover)").matches)return;const e=document.querySelectorAll(".bento-card");e.forEach(e=>{e.addEventListener("mousemove",t=>{const n=e.getBoundingClientRect(),i=t.clientX-n.left,a=t.clientY-n.top,s=n.width/2,o=n.height/2,r=(i-s)/s*8,c=(o-a)/o*8;e.style.setProperty("--rotate-x",`${c}deg`),e.style.setProperty("--rotate-y",`${r}deg`)}),e.addEventListener("mouseleave",()=>{e.style.setProperty("--rotate-x","0deg"),e.style.setProperty("--rotate-y","0deg")})})}function t(){const e=document.getElementById("searchInput"),t=document.getElementById("clearBtn"),i=document.querySelectorAll(".filter-pill"),a=document.querySelectorAll(".bento-card"),r=document.getElementById("noResults");let n="all";function o(){const s=e.value.toLowerCase().trim();let o=0;a.forEach(e=>{const i=e.dataset.title.toLowerCase(),a=e.dataset.summary.toLowerCase(),t=e.dataset.tags.toLowerCase(),r=!s||i.includes(s)||a.includes(s)||t.includes(s),c=n==="all"||t.split(",").some(e=>e.trim().toLowerCase()===n.toLowerCase());r&&c?(e.classList.remove("hidden"),o++):e.classList.add("hidden")}),r.style.display=o===0?"block":"none",t.style.display=s?"flex":"none"}const c=s(o,300);e.addEventListener("input",c),t.addEventListener("click",()=>{e.value="",t.style.display="none",o(),e.focus()}),i.forEach(e=>{e.addEventListener("click",()=>{i.forEach(e=>e.classList.remove("active")),e.classList.add("active"),n=e.dataset.category,o()})})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",()=>{e(),t()}):(e(),t());let n;window.addEventListener("resize",()=>{clearTimeout(n),n=setTimeout(e,250)})})()</script></div><footer class=modern-footer><div class=footer-glow></div><div class=footer-container><div class=footer-content><div class=footer-brand><span class=brand-name>Deepak Baby</span><p class=brand-tagline>Senior Data Scientist at KBC Bank & Verzekering</p></div><div class=footer-social><a href=mailto:deepakbabycet@gmail.com class=social-icon aria-label=Email title=Email><i class="fas fa-envelope"></i>
</a><a href=https://www.github.com/deepakbaby class=social-icon target=_blank rel="noopener noreferrer" aria-label=Github title=Github><i class="fab fa-github"></i>
</a><a href=https://www.linkedin.com/in/deepakbaby/ class=social-icon target=_blank rel="noopener noreferrer" aria-label=LinkedIn title=LinkedIn><i class="fab fa-linkedin"></i>
</a><a href="https://scholar.google.com/citations?user=69q7FOYAAAAJ&amp;hl=en" class=social-icon target=_blank rel="noopener noreferrer" aria-label="Google Scholar" title="Google Scholar"><i class="fa-brands fa-google-scholar"></i></a></div><div class=footer-links><a href=#hero>Home</a>
<a href=#about>About</a>
<a href=#experiences>Experience</a>
<a href=#posts>Blog</a>
<a href=#publications>Publications</a></div></div><div class=footer-bottom><p class=copyright>© 2025 Deepak Baby. All rights reserved.</p><p class=credits>Made with <span class=heart>❤</span>, Hugo and Claude</p></div></div></footer><style>.modern-footer{position:relative;background:#050506;padding:4rem 0 2rem;overflow:hidden}.footer-glow{position:absolute;top:0;left:50%;transform:translateX(-50%);width:600px;height:2px;background:linear-gradient(90deg,transparent 0%,#3b82f6 25%,#1d4ed8 50%,#3b82f6 75%,transparent 100%);filter:blur(1px)}.footer-container{max-width:1200px;margin:0 auto;padding:0 2rem}.footer-content{display:flex;flex-direction:column;align-items:center;text-align:center;gap:2rem;margin-bottom:3rem}.footer-brand{margin-bottom:.5rem}.brand-name{font-size:1.5rem;font-weight:700;background:linear-gradient(135deg,#fff 0%,#a78bfa 100%);-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text}.brand-tagline{font-size:.9rem;color:#6b7280;margin:.5rem 0 0}.footer-social{display:flex;gap:1rem}.social-icon{width:44px;height:44px;border-radius:50%;background:rgba(255,255,255,5%);border:1px solid rgba(255,255,255,8%);display:flex;align-items:center;justify-content:center;color:#9ca3af;font-size:1.1rem;text-decoration:none;transition:all .3s ease}.social-icon:hover{background:linear-gradient(135deg,#8b5cf6 0%,#3b82f6 100%);border-color:transparent;color:#fff;transform:translateY(-4px);box-shadow:0 8px 25px rgba(139,92,246,.3)}.footer-links{display:flex;flex-wrap:wrap;justify-content:center;gap:1.5rem}.footer-links a{color:#6b7280;text-decoration:none;font-size:.9rem;transition:color .3s}.footer-links a:hover{color:#a78bfa}.footer-bottom{border-top:1px solid rgba(255,255,255,5%);padding-top:2rem;display:flex;flex-direction:column;align-items:center;gap:.5rem}.copyright{font-size:.875rem;color:#4b5563;margin:0}.credits{font-size:.75rem;color:#374151;margin:0}.heart{color:#ef4444;animation:heartbeat 1.5s infinite}@keyframes heartbeat{0%,100%{transform:scale(1)}50%{transform:scale(1.2)}}@media(min-width:768px){.footer-content{flex-direction:row;justify-content:space-between;text-align:left}.footer-bottom{flex-direction:row;justify-content:space-between}}</style><script src=/application.f6959e0d840b2a0cb8ebdc7b64f82c76ed540bafda2e2f31ece1d91e812ba4d1.js integrity="sha256-9pWeDYQLKgy469x7ZPgsdu1UC6/aLi8x7OHZHoErpNE=" defer></script><script src=/js/collapsible-sidebars.js></script></body></html>