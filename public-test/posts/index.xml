<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Deepak Baby</title><link>https://deepakbaby.in/posts/</link><description>Recent content in Posts on Deepak Baby</description><generator>Hugo</generator><language>en</language><lastBuildDate>Wed, 03 Dec 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deepakbaby.in/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Slides: Distributed Training for ML</title><link>https://deepakbaby.in/posts/distributed-training-presentation/</link><pubDate>Wed, 03 Dec 2025 00:00:00 +0000</pubDate><guid>https://deepakbaby.in/posts/distributed-training-presentation/</guid><description>&lt;p>Explore distributed training techniques through this interactive presentation. Navigate through the slides using arrow keys or the navigation controls.&lt;/p>
&lt;h2 id="topics-covered">Topics Covered&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Back to Basics&lt;/strong>: Understanding neural network fundamentals&lt;/li>
&lt;li>&lt;strong>Why Distributed Training&lt;/strong>: Memory constraints and scaling challenges&lt;/li>
&lt;li>&lt;strong>DDP (Data Distributed Parallel)&lt;/strong>: Replicating models across GPUs&lt;/li>
&lt;li>&lt;strong>Pipeline Parallelism&lt;/strong>: Splitting models across devices&lt;/li>
&lt;li>&lt;strong>FSDP (Fully Sharded Data Parallel)&lt;/strong>: Advanced sharding techniques&lt;/li>
&lt;/ul>
&lt;h2 id="slides">Slides&lt;/h2>
&lt;p>Use the arrow keys (← →) or click the navigation arrows to move between slides. Some slides include animations that you can step through using the animation controls at the bottom.&lt;/p></description></item><item><title>Distributed Training Techniques: DDP, Pipeline Parallelism, and FSDP</title><link>https://deepakbaby.in/posts/distributed-training/</link><pubDate>Mon, 01 Dec 2025 00:00:00 +0000</pubDate><guid>https://deepakbaby.in/posts/distributed-training/</guid><description>&lt;p>Modern deep learning models have grown exponentially in size and complexity. GPT-4 has over a trillion parameters, and even &amp;ldquo;smaller&amp;rdquo; models like LLaMA-70B require substantial computational resources. Training or fine-tuning such models on a single GPU is often impossible; not just because of time constraints, but because the model itself may not fit in the memory of a single device. This is where &lt;strong>distributed training&lt;/strong> becomes essential.&lt;/p>
&lt;h2 id="why-do-we-need-distributed-training">Why Do We Need Distributed Training?&lt;/h2>
&lt;h3 id="the-memory-wall-problem">The Memory Wall Problem&lt;/h3>
&lt;p>A modern GPU like the NVIDIA A100 has 80GB of memory. Sounds like a lot? Let&amp;rsquo;s do some math:&lt;/p></description></item><item><title>NICE- Non-linear Independent Components Estimation: Insights and Implementation in Keras</title><link>https://deepakbaby.in/posts/nice-keras/</link><pubDate>Tue, 03 Dec 2019 12:55:51 +0100</pubDate><guid>https://deepakbaby.in/posts/nice-keras/</guid><description>&lt;p>Keras implementation can be found &lt;a href="https://deepakbaby.github.io/post/nice-keras/">here&lt;/a>.&lt;/p>
&lt;p>Flow-based deep generative models have not gained much attention in the research community when compared to &lt;a href="https://arxiv.org/abs/1406.2661">GANs&lt;/a> or &lt;a href="https://arxiv.org/abs/1312.6114">VAEs&lt;/a>. This post discusses a flow-based model called &lt;a href="https://arxiv.org/abs/1410.8516">NICE&lt;/a>, its advantages over the other generative models and finally an implementation in Keras.&lt;/p>
&lt;p>While VAEs use an encoder that finds only an approximation of the latent variable corresponding to a datapoint, GANs doesnt even have an encoder to infer latents. In flow-based models, the latent variables can be infered exactly without any approximation. Flow-based models make use of reversible architecture (which will be explained below) which enables accurate inference, in addition to providing optimization over the exact log-likelihood of the data instead of a lower bound of it.&lt;/p></description></item><item><title>Implementing Variational Autoencoders: Insights and some tricks</title><link>https://deepakbaby.in/posts/vae-insights/</link><pubDate>Wed, 03 Jul 2019 15:53:58 +0200</pubDate><guid>https://deepakbaby.in/posts/vae-insights/</guid><description>&lt;p>This post is a summary of some of the main hurdles I encountered in implementing a VAE on a custom dataset and the tricks I used to solve them. The keras code snippets are also provided. Understanding VAEs and its basic implementation in Keras can be found in the &lt;a href="https://deepakbaby.github.io/post/vae-keras/">previous post&lt;/a>.&lt;/p>
&lt;h2 id="posterior-collapse-in-vaes">Posterior collapse in VAEs&lt;/h2>
&lt;p>The Goal of VAE is to train a generative model $\mathbb{P}(\mathbf{X}, z)$ to maximize the marginal likelihood $\mathbb{\mathbf{X}}$ of the dataset. The cost function used in training a VAE is comprised of a reconstruction loss and a KL loss as given below.&lt;/p></description></item><item><title>Understanding Variational Autoencoders and Implementation in Keras</title><link>https://deepakbaby.in/posts/vae-keras/</link><pubDate>Tue, 02 Jul 2019 16:44:25 +0200</pubDate><guid>https://deepakbaby.in/posts/vae-keras/</guid><description>&lt;p>Variational Autoencoders (VAEs)&lt;a href="https://arxiv.org/abs/1312.6114">[Kingma, et.al (2013)]&lt;/a> let us design complex generative models of data that can be trained on large datasets. This post is about understanding the VAE concepts, its loss functions and how we can implement it in keras.&lt;/p>
&lt;h2 id="generating-data-from-a-latent-space">Generating data from a latent space&lt;/h2>
&lt;p>VAEs, in terms of probabilistic terms, assume that the data-points in a large dataset are generated from a latent space. For e.g., let us assume we want to generate the image of an animal. First we imagine that it has four legs, a head and a tail. This is analogous to the latent space and from this set of characteristics that are defined in the latent space, the model will learn to generate the image of an animal.&lt;/p></description></item><item><title>Installing Kaldi with MKL support without root access</title><link>https://deepakbaby.in/posts/kaldi-mkl/</link><pubDate>Tue, 21 May 2019 13:51:12 +0200</pubDate><guid>https://deepakbaby.in/posts/kaldi-mkl/</guid><description>&lt;p>Kaldi has recently switched to Intel Math Kernel Libraries (MKL) for linear algebra operations (as of April 2019). However, installing MKL (by running &lt;code>tools/extras/install_mkl.sh&lt;/code>) requires root access. This post details how kaldi (with MKL) can be installed without root access.&lt;/p>
&lt;ol>
&lt;li>Download &lt;a href="https://kaldi-asr.org/doc/install.html">Kaldi&lt;/a>&lt;/li>
&lt;li>Download the MKL standalone installer from &lt;a href="https://software.intel.com/en-us/mkl/choose-download/linux">here&lt;/a>.
&lt;ul>
&lt;li>Extract the contents and launch the installer by running &lt;code>install.sh&lt;/code>.&lt;/li>
&lt;li>When asked for the path to install, specify a location where you have write access (e.g., &lt;code>/home/&amp;lt;username&amp;gt;/intel&lt;/code>)&lt;/li>
&lt;li>Complete the installation of MKL libraries&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Navigate to the kaldi folder &lt;code>kaldi/tools&lt;/code>&lt;/li>
&lt;li>Typically the first step is to run &lt;code>extras/check_dependencies.sh&lt;/code>. This will complain about the missing MKL libraries. This is because the script expects the MKL libraries to be located under &lt;code>/opt/intel&lt;/code> directory. As of now (May 2019), there is no option to pass the &lt;code>mkl-root&lt;/code> directory to this script. Therefore we will edit the &lt;code>extras/check_dependencies.sh&lt;/code> script by changing &lt;code>/opt/intel/mkl/include/mkl.h&lt;/code> to &lt;code>/home/&amp;lt;username&amp;gt;/intel/mkl/include/mkl.h&lt;/code>. Then running &lt;code>extras/check_dependencies.sh&lt;/code> should work fine without any MKL related warnings.&lt;/li>
&lt;li>Then run &lt;code>make -j &amp;lt;numcpu&amp;gt;&lt;/code> to install the tools required by kaldi&lt;/li>
&lt;li>Navigate to the &lt;code>kaldi/src&lt;/code> folder.&lt;/li>
&lt;li>Run &lt;code>./configure&lt;/code> with the &lt;code>--mkl-root&lt;/code> option.
&lt;pre tabindex="0">&lt;code>./configure --shared --mkl-root=/home/&amp;lt;username&amp;gt;/intel/mkl
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>Then install kaldi using the usual steps
&lt;pre tabindex="0">&lt;code>make depend -j &amp;lt;numcpu&amp;gt; 
make -j &amp;lt;numcpu&amp;gt;
&lt;/code>&lt;/pre>&lt;/li>
&lt;/ol>
&lt;p>This will install Kaldi with MKL support without requiring any root privileges.&lt;/p></description></item><item><title>Training kaldi models with custom features</title><link>https://deepakbaby.in/posts/kaldi-custom-features/</link><pubDate>Wed, 06 Mar 2019 12:30:39 +0100</pubDate><guid>https://deepakbaby.in/posts/kaldi-custom-features/</guid><description>&lt;p>&lt;a href="https://github.com/kaldi-asr/kaldi">Kaldi Speech Recognition Toolkit&lt;/a> is a freely available toolkit that offers several tools for conducting research on automatic speech recognition (ASR). It lets us train an ASR system from scratch all the way from the feature extraction (MFCC,FBANK, ivector, FMLLR,&amp;hellip;), GMM and DNN acoustic model training, to the decoding using advanced language models, and produce state-of-the-art results.&lt;/p>
&lt;p>While kaldi offers so much flexibilty at every stage, sometimes we also need to play with features that are not offered by the kaldi repository. Kaldi makes use of ark format to store the features. If we want to perform experiments with customized features, they must be converted to the ark format first. The goal of this post is to explain how we can extract and store the custom features in the ark format using matlab and python.&lt;/p></description></item><item><title>Tracking Multiple Losses with Keras</title><link>https://deepakbaby.in/posts/keras-multiple-losses/</link><pubDate>Mon, 04 Mar 2019 11:59:56 +0100</pubDate><guid>https://deepakbaby.in/posts/keras-multiple-losses/</guid><description>&lt;p>Often we deal with networks that are optimized for multiple losses (e.g., VAE). In such scenarios, it is useful to keep track of each loss independently, for fine-tuning its contribution to the overall loss. This post details an example on how to do this with keras.&lt;/p>
&lt;p>Let us look at an example model which needs to trained to minimize the sum of two losses, say mean square error (MSE) and mean absolute error (MAE). Let $\lambda_{mse}$ be the hyperparameter that controls the contribution of MSE to the toal loss. i.e., the total loss is MAE + $\lambda_{mse}$ * MSE. This loss can be implemented using:&lt;/p></description></item><item><title>Tensorflow-GPU in multi-user environment</title><link>https://deepakbaby.in/posts/cochlear-ugent/</link><pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate><guid>https://deepakbaby.in/posts/cochlear-ugent/</guid><description>&lt;p>This post is intended for setting up tensorflow-gpu setup in a multi-user setting. This is written as a guide for GPU users at the WAVES research group, Ghent University, Belgium. But these are also applicable to any linux multi-user environment with GPU-based jobs.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://deepakbaby.in/posts/cochlear-ugent/#installing-tensorflow-in-conda">Installing Tensorflow in conda&lt;/a>
&lt;ul>
&lt;li>&lt;a href="https://deepakbaby.in/posts/cochlear-ugent/#conda-installation">conda installation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deepakbaby.in/posts/cochlear-ugent/#conda-tensorflow">conda tensorflow&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deepakbaby.in/posts/cochlear-ugent/#testing-tensorflow-installation">Testing Tensorflow Installation&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://deepakbaby.in/posts/cochlear-ugent/#admin-only">Admin only&lt;/a>
&lt;ul>
&lt;li>&lt;a href="https://deepakbaby.in/posts/cochlear-ugent/#installing-the-cuda-compiler-and-nvidia-drivers">Installing the cuda compiler and nvidia drivers&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="installing-tensorflow-in-conda">Installing Tensorflow in conda&lt;/h2>
&lt;h3 id="conda-installation">conda installation&lt;/h3>
&lt;p>Anaconda is a popular python environment among the AI/ML community. The anaconda distribution can be downloaded from &lt;a href="https://www.anaconda.com/download/">here&lt;/a>. Follow the instructions &lt;a href="https://docs.anaconda.com/anaconda/install/linux/">here&lt;/a> to properly install it to your user account.&lt;/p></description></item><item><title>Google Duplex</title><link>https://deepakbaby.in/posts/ai-5/</link><pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate><guid>https://deepakbaby.in/posts/ai-5/</guid><description>&lt;p>ഒരു കമ്പ്യൂട്ടർ നിങ്ങൾക്കുവേണ്ടി ഒരു ബാർബർ ഷോപ്പിലേക്കോ ഹോട്ടലിലേക്കോ ഫോൺ ചെയ്തു റിസർവേഷൻ എടുത്തുതരുന്ന കാലത്തെപ്പറ്റി നിങ്ങൾ ചിന്തിച്ചിട്ടുണ്ടോ? എങ്കിൽ അറിയുക, നാം അവിടെയെത്തിയെന്ന്! അതാണ് ഗൂഗിൾ ഡ്യൂപ്ളെക്സ് (Google Duplex) .&lt;/p>
&lt;p>&lt;a href="https://4.bp.blogspot.com/-Zf3Sf3FC40c/WvQ8BswB7qI/AAAAAAAACrQ/CllRLs2_uTMz5yvQHd93NPzx9ZEwP_zWwCLcBGAs/s1600/google-duplex.jpg">&lt;img src="https://4.bp.blogspot.com/-Zf3Sf3FC40c/WvQ8BswB7qI/AAAAAAAACrQ/CllRLs2_uTMz5yvQHd93NPzx9ZEwP_zWwCLcBGAs/s320/google-duplex.jpg" alt="">&lt;/a>&lt;/p>
&lt;p>&lt;strong>ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ് ഭാഗം- 5&lt;/strong>&lt;/p>
&lt;p>AI രംഗത്തെ ഏറ്റവും പ്രധാനപ്പെട്ട നാഴികക്കല്ലുകളിലൊന്നിനാണ് നമ്മൾ ഇന്നലെ സാക്ഷ്യം വഹിച്ചത്. നമുക്കുവേണ്ടി ഫോൺ കാളുകൾ നടത്താനും അവിടെയുള്ളവരോട് സംസാരിക്കാനും കഴിയുന്ന AI സംവിധാനമായ Google Duplex ഇന്നലെ ഗൂഗിൾ അവതരിപ്പിച്ചു (വീഡിയോ കാണുക). Google assistant കുറെ കാലമായി നമ്മൾ കണ്ടിരുന്നതാണെങ്കിലും അതിനു ധാരാളം പരിമിതികളുണ്ടായിരുന്നു. അതിൽനിന്നൊക്കെ വളരെയധികം മുന്നോട്ടുപോയ ഒരു മനുഷ്യൻതന്നെയെന്നു തോന്നിപ്പിക്കുമാറ് നമ്മുടെ സംസാരത്തിലെ ചെറിയ കാര്യങ്ങൾ വരെ (ഇടക്കുള്ള pause, hmmm, err ശബ്ദങ്ങൾ) ഉൾപ്പെടുത്തിയാണ് ഈ AI സംവിധാനം സംസാരിക്കുന്നത്!&lt;/p></description></item><item><title>ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 4</title><link>https://deepakbaby.in/posts/ai-4/</link><pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate><guid>https://deepakbaby.in/posts/ai-4/</guid><description>&lt;p>ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് ഗവേഷണത്തിൽ ഇന്ന് ഏറ്റവുമധികം ഉപയോഗത്തിലിരിക്കുന്ന ന്യൂറൽ നെറ്റ്‌വർക്കുകളെ കുറിച്ചാണ് കഴിഞ്ഞ ഭാഗത്തിൽ പറഞ്ഞത് (കഴിഞ്ഞ ഭാഗം &lt;a href="https://dblogsai.blogspot.be/2018/05/3.html">ഇവിടെ&lt;/a> വായിക്കാം). ഇനി ചരിത്രത്തിലെ രണ്ടാം ഘട്ടത്തിലേക്ക്. മുമ്പുപറഞ്ഞതുപോലെ ന്യൂറൽ നെറ്റ്‌വർക്കുമായി ബന്ധപ്പെട്ട ആദ്യകാല ശ്രമങ്ങളും ഗവേഷണങ്ങളുമാണ് ഈ ഭാഗത്തിൽ.&lt;/p>
&lt;p>&lt;strong>1943 - ഇലെക്ട്രിക്കൽ സർക്യൂട്ടുകൾ ഉപയോഗിച്ച് ഒരു ന്യൂറൽ നെറ്റ്‌വർക്ക് നിർമ്മിക്കപ്പെട്ടു&lt;/strong>&lt;br>
നമ്മുടെ ന്യൂറോണുകൾ എങ്ങനെയായിരിക്കും പ്രവർത്തിക്കുന്നത് എന്നതിനെപ്പറ്റി ന്യൂറോഫൈസിയോളജിസ്റ്റായ വാറൻ മക്കുല്ലോഷും ഗണിതജ്ഞനായ വാൾട്ടർ പിട്സും ചേർന്ന് ഒരു സിദ്ധാന്തം അവതരിപ്പിച്ചു. അതിന്റെ ഒരു ചെറിയ മോഡൽ ഇലെക്ട്രിക്കൽ സർക്യൂട്ടുകൾ ഉപയോഗിച്ച് അവർ നിർമിക്കുകയും ചെയ്തു. നമ്മുടെ ശരീരത്തിലെ ന്യൂറോണുകളുടെ പ്രവർത്തനത്തെപ്പറ്റി അനുലഭ്യമായിരുന്ന പരിമിതമായ അറിവുവച്ചാണ് അത്തരമൊരു മാതൃക അവർ നിർമ്മിച്ചത്.&lt;br>
&lt;strong>1952- checkers game കളിക്കുന്ന കമ്പ്യൂട്ടർ&lt;/strong>&lt;/p></description></item><item><title>ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 3</title><link>https://deepakbaby.in/posts/ai-3/</link><pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate><guid>https://deepakbaby.in/posts/ai-3/</guid><description>&lt;h3 id="നയറൽ-നററവർകകകൾ">ന്യൂറൽ നെറ്റ്‌വർക്കുകൾ &lt;/h3>
&lt;p>1950 കൾക്ക് മുൻപുള്ള, ഇന്നത്തെ കമ്പ്യൂട്ടർ സയൻസിന്റെയും ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസിന്റെയും വളർച്ചക്ക് വിത്തുപാകിയ ചില സിദ്ധാന്തങ്ങളാണ് കഴിഞ്ഞ ഭാഗത്തിൽ പറഞ്ഞത്. അത്തരം സിദ്ധാന്തങ്ങളിൽ നിന്നും പ്രചോദനമുൾക്കൊണ്ട് പ്രവർത്തിക്കുന്ന യന്ത്രങ്ങൾ 1950 കൾക്ക് ശേഷമാണ് യാഥാർഥ്യമായത്. അന്നുമുതൽ 2006 വരെയുള്ള കാലമാണ് AI ചരിത്രത്തിലെ രണ്ടാം ഘട്ടം. അതിലേക്കു കടക്കുന്നതിനുമുന്പ് നമ്മൾ ന്യൂറൽ നെറ്റ്‌വർക്ക് എന്താണെന്ന് മനസിലാക്കേണ്ടതുണ്ട്.&lt;/p>
&lt;p>കൃത്രിമബുദ്ധി അഥവാ AI എന്നത് മഷിനുകൾക്കു മനുഷ്യനെപ്പോലെ ചിന്തിക്കാനുള്ള ബുദ്ധി കൃത്രിമമായി നിർമിക്കുന്ന പ്രക്രിയയാണ്. നമ്മുടെ തലച്ചോറിനെയും, അതിലേക്കു ബന്ധപ്പെട്ടിരിക്കുന്ന, നമ്മുടെ ഇന്ദ്രിയങ്ങളിൽനിന്നും സിഗ്നലുകൾ അവിടേക്കെത്തിക്കുന്ന ന്യൂറോണുകളെയും അടിസ്ഥാനപ്പെട്ടാണ് നമ്മുടെ ബുദ്ധി ഇരിക്കുന്നത്. നമ്മുടെ തലച്ചോറിൽ 100 ബില്യണിലധികം ന്യൂറോണുകൾ ഉണ്ടെന്നാണ് കണക്ക്. നമ്മുടെ ഇന്ദ്രിയങ്ങളിൽ നിന്നും വരുന്ന ഇത്തരം കോടിക്കണക്കിനു സിഗ്നലുകളെ ക്രോഡീകരിച്ചാണ് നമ്മുടെ തലച്ചോറ് സംവേദനം (പെർസെപ്ഷൻ) എന്നത് സാധ്യമാക്കുന്നത്. ഉദാഹരണം പറഞ്ഞാൽ, നാം ഒരാളെ കാണുമ്പോൾ അയാളിൽനിന്നും വരുന്ന പ്രകാശകിരണങ്ങൾ നമ്മുടെ കണ്ണിൽ പതിക്കുകയും ആ കിരണങ്ങൾക്കനുസൃതമായി കണ്ണിൽ നിന്നും സിഗ്നലുകൾ തലച്ചോറിലേക്ക് ന്യൂറോണുകൾ എത്തിക്കുകയും ചെയ്യും. ഈ സിഗ്നലുകളിൽ നിന്നാണ് നമ്മുടെ തലച്ചോറ് നാം ആ ആളെ കണ്ടു എന്ന തോന്നൽ അല്ലെങ്കിൽ perception ഉണ്ടാക്കുന്നത്. കാഴ്ചക്ക് തലച്ചോറിലെ visual cortex എന്ന ഭാഗമാണ് പ്രധാനമായും ഉപയോഗിക്കുന്നത്. നമ്മുടെ തലച്ചോറ് ന്യൂറോണുകളിൽനിന്നും വരുന്ന സിഗ്നലുകളെ എങ്ങനെ ക്രോഡീകരിക്കുന്നു എന്നത് ഇന്നും നമുക്കധികം മനസിലാകാത്ത വിഷയമാണ്. അത് അറിയില്ലാത്തതുകൊണ്ടാണ് AI തീരുമാനങ്ങൾ (decision making ) എടുക്കാൻ മറ്റു സങ്കേതങ്ങൾ ഉപയോഗിക്കുന്നതും. (മറ്റു സങ്കേതങ്ങളെ പറ്റി വരും ഭാഗങ്ങളിൽ പറയാം)&lt;/p></description></item><item><title>ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്: ഭാഗം - 2</title><link>https://deepakbaby.in/posts/ai-2/</link><pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate><guid>https://deepakbaby.in/posts/ai-2/</guid><description>&lt;p>യന്ത്രങ്ങൾ കണ്ടുപിടിച്ച കാലം മുതൽക്കേ മനുഷ്യനെ ത്രസിപ്പിച്ചിരുന്ന ആശയമായിരുന്നു സ്വയബുദ്ധിയോടെ പ്രവർത്തിക്കുന്ന യന്ത്രങ്ങൾ. കുറെ യന്ത്രഭാഗങ്ങളുടെ ചലനത്തെമാത്രം അടിസ്ഥാനമാക്കി പ്രവർത്തിച്ചിരുന്ന യന്ത്രങ്ങളിൽ നിന്ന് ഇന്നു നമ്മുടെ സാങ്കേതികവിദ്യ വളരെയേറെ മുന്നോട്ടുപോയിരിക്കുന്നു. ആ വഴിയിലെ ചില പ്രധാനപ്പെട്ട കണ്ടുപിടുത്തങ്ങളാണ് ഈ ഭാഗത്തിൽ.&lt;/p>
&lt;p>ഈ ചരിത്രത്തെ മൂന്ന് ഘട്ടങ്ങളായി തിരിക്കാം. കംപ്യൂട്ടർ എന്ന മെഷിൻ നിര്മിക്കപ്പെടുന്നതിനുമുമ്പ് ഇങ്ങനെയൊരു മഷിന്റെ സാധ്യതകളെക്കുറിച്ചു ചില സിദ്ധാന്തങ്ങൾ അവതരിപ്പിക്കപ്പെട്ടു. ഇന്നത്തെ കംപ്യൂട്ടറുകൾ പലതും അത്തരം സിദ്ധാന്തങ്ങൾ അടിസ്ഥാനമാക്കി നിർമിക്കപ്പെട്ടവയാണ്. 1950 നു മുൻപുള്ള ആ കാലഘട്ടത്തിലെ പ്രധാന നാഴികക്കല്ലുകളാണ് ഈ ഭാഗത്തിൽ. സിദ്ധാന്തങ്ങളിൽ നിന്നും കമ്പ്യൂട്ടർ എന്ന മെഷിൻ എങ്ങനെയാണ് യാഥാർഥ്യമായതു എന്നതും അതിനോടൊപ്പം മെഷീൻ ലേർണിംഗ്/ കൃത്രിമബുദ്ധി ഉണ്ടാക്കാനുള്ള ശ്രമങ്ങളുമാണ് രണ്ടാം ഭാഗം. അത് 1980 കളോടെ അവസാനിക്കും. പിന്നീട് AI ഗവേഷണം ഉയർത്തെഴുന്നേൽക്കുന്നത് 2006 ലാണ്. അന്നുതൊട്ടുള്ള ചെറുചരിത്രവും അതിനു ചുക്കാൻപിടിച്ച ഇന്നത്തെ പ്രമുഖരായ ഗവേഷകരെപ്പറ്റിയുമായിരിക്കും മൂന്നാം ഭാഗം. &lt;/p></description></item><item><title>മെഷീൻ ലേണിങ്/ ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് സീരീസ്</title><link>https://deepakbaby.in/posts/ai-1/</link><pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate><guid>https://deepakbaby.in/posts/ai-1/</guid><description>&lt;p>&lt;a href="https://4.bp.blogspot.com/-8BFn6e85j88/WvBTIQ_yDvI/AAAAAAAACqY/vtIzPXmjvEQtDHwd03uS1P51enEttcDbACPcBGAYYCw/s1600/ml.jpg">&lt;img src="https://4.bp.blogspot.com/-8BFn6e85j88/WvBTIQ_yDvI/AAAAAAAACqY/vtIzPXmjvEQtDHwd03uS1P51enEttcDbACPcBGAYYCw/s320/ml.jpg" alt="">&lt;/a>&lt;/p>
&lt;p>കേംബ്രിഡ്ജ് അനാലിറ്റിക്കയും അതുവഴി ഫേസ്ബുക് പിടിച്ച പുലിവാലുമൊക്കെ എല്ലാവരും അറിഞ്ഞിരിക്കുമല്ലോ. ഉപയോക്താക്കളുടെ വിവരങ്ങൾ ചോർത്തി, ആ വിവരങ്ങൾ ഉപയോഗിച്ച് നമ്മുടെ ചിന്തകളെ സ്വാധീനിക്കുന്ന തരം പോസ്റ്റുകൾ നമ്മുടെ ന്യൂസ് ഫീഡിലേക്ക് കടത്തിവിടുകയാണ് കേംബ്രിഡ്ജ് അനാലിറ്റിക്ക ചെയ്തതെന്നും പലരും വായിച്ചിരിക്കും. എന്നാൽ എങ്ങനെയാണ് ഒരാളുടെ വിവരങ്ങളിൽ നിന്നും ഇതെല്ലാം മനസിലാക്കി, എന്തുതരം പോസ്റ്റുകൾ ഇടണം എന്ന തീരുമാനം എടുക്കുന്നതെന്നു പലർക്കും മനസിലായിട്ടുണ്ടാവില്ല. ഇത്രയധികം ഉപയോക്താക്കളുടെ ഡാറ്റ പരിശോധിച്ച് അവരുടെ അഭിരുചികൾ മനസിലാക്കി കൃത്യമായ പോസ്റ്റുകൾ കടത്തിവിടാൻ ഒരു മനുഷ്യനെക്കൊണ്ടു സാധിക്കില്ലെന്നുറപ്പ്. അപ്പോൾ പിന്നെ അത് കമ്പ്യൂട്ടർ തന്നെ.&lt;/p>
&lt;p>എന്നാലും കമ്പ്യൂട്ടർ ഒരു മെഷിനല്ലേ. അതിനു ഇത്തരത്തിലൊരു കഴിവുണ്ടോ ? കംപ്യൂട്ടറുകൾ സത്യത്തിൽ വെറും മണ്ടന്മാരാണ്. അതിനു ആകെക്കൂടെ കുറെ സംഖ്യകളെ കൂട്ടാനും കുറക്കാനും ഗുണിക്കാനും ഹരിക്കാനും അറിയാം.. നമ്മൾ മനുഷ്യരെപോലെ പഞ്ചേന്ദ്രിയങ്ങളോ അവയിൽനിന്നു വരുന്ന വിവരങ്ങളെ ഏകോപിപ്പിക്കുന്ന ഒരു തലച്ചോറോ ഇല്ല. നമ്മുടെ വിവരങ്ങളെല്ലാം കമ്പ്യൂട്ടറുകൾ കാണുന്നത് സംഖ്യകൾ ആയിട്ടാണ്. എല്ലാവര്ക്കും ബൈനറി നമ്പർ സിസ്റ്റം അറിയാമെന്നു കരുതുന്നു. കമ്പ്യൂട്ടറിൽ എല്ലാം 1 അല്ലെങ്കിൽ 0 ആയിട്ടാണ് എല്ലാം ശേഖരിച്ചുവച്ചിരിക്കുന്നത്. ഇങ്ങനെയുള്ള കുറെ ഒന്നുകളിൽ നിന്നും പൂജ്യങ്ങളിൽ നിന്നും കമ്പ്യൂട്ടറിനെ ഒരു തീരുമാനം എടുക്കാൻ പഠിപ്പിക്കുന്ന ശാസ്ത്രശാഖയാണ് ആർട്ടിഫിഷ്യൽ ഇന്റലിജൻസ് അഥവാ മെഷീൻ ലേർണിംഗ്.&lt;/p></description></item><item><title>A quick start guide for Linux users at Intec</title><link>https://deepakbaby.in/posts/ugent-linux/</link><pubDate>Tue, 06 Jun 2017 00:00:00 +0000</pubDate><guid>https://deepakbaby.in/posts/ugent-linux/</guid><description>&lt;ul>
&lt;li>&lt;a href="https://deepakbaby.in/posts/ugent-linux/#what-does-this-guide-offer?">What does this guide offer?&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deepakbaby.in/posts/ugent-linux/#software-packages-and-os">Software packages and OS&lt;/a>
&lt;ul>
&lt;li>&lt;a href="https://deepakbaby.in/posts/ugent-linux/#install-a-linux-os">Install a linux OS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deepakbaby.in/posts/ugent-linux/#openvpn">Openvpn&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deepakbaby.in/posts/ugent-linux/#matlab">Matlab&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://deepakbaby.in/posts/ugent-linux/#miscellaneous">Miscellaneous&lt;/a>
&lt;ul>
&lt;li>&lt;a href="https://deepakbaby.in/posts/ugent-linux/#configuring-the-printer">Configuring printer&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deepakbaby.in/posts/ugent-linux/#before-using-apollo-webpage">Before using apollo webpage&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deepakbaby.in/posts/ugent-linux/#mounting-intec-file-share">Mounting Intec file share&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="what-does-this-guide-offer">What does this guide offer?&lt;/h2>
&lt;p>This report aims as a quick guide for setting up linux machines in Intec, UGent. It may not contain help on everything, but the goal is to keep adding things as we encounter and solve them. The instructions are for fedora 25, unless otherwise mentioned. For other linux distributions, you might need to appropriately change the command-line instructions.&lt;/p></description></item><item><title>Introduction</title><link>https://deepakbaby.in/posts/introduction/</link><pubDate>Thu, 08 Jun 2000 08:06:25 +0600</pubDate><guid>https://deepakbaby.in/posts/introduction/</guid><description>&lt;p>Greeting! This is an introduction post. This post tests the followings:&lt;/p>
&lt;ul>
&lt;li>Hero image is in the same directory as the post.&lt;/li>
&lt;li>This post should be at top of the sidebar.&lt;/li>
&lt;li>Post author should be the same as specified in &lt;code>author.yaml&lt;/code> file.&lt;/li>
&lt;/ul></description></item><item><title>Markdown Samples</title><link>https://deepakbaby.in/posts/markdown-sample/</link><pubDate>Thu, 08 Jun 2000 08:06:25 +0600</pubDate><guid>https://deepakbaby.in/posts/markdown-sample/</guid><description>&lt;p>This is a sample post intended to test the followings:&lt;/p>
&lt;ul>
&lt;li>A different post author.&lt;/li>
&lt;li>Table of contents.&lt;/li>
&lt;li>Markdown content rendering.&lt;/li>
&lt;li>Math rendering.&lt;/li>
&lt;li>Emoji rendering.&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="markdown-syntax-rendering">Markdown Syntax Rendering&lt;/h1>
&lt;h2 id="headings">Headings&lt;/h2>
&lt;p>The following HTML &lt;code>&amp;lt;h1&amp;gt;&lt;/code>—&lt;code>&amp;lt;h6&amp;gt;&lt;/code> elements represent six levels of section headings. &lt;code>&amp;lt;h1&amp;gt;&lt;/code> is the highest section level while &lt;code>&amp;lt;h6&amp;gt;&lt;/code> is the lowest.&lt;/p>
&lt;h1 id="h1">H1&lt;/h1>
&lt;h2 id="h2">H2&lt;/h2>
&lt;h3 id="h3">H3&lt;/h3>
&lt;h4 id="h4">H4&lt;/h4>
&lt;h5 id="h5">H5&lt;/h5>
&lt;h6 id="h6">H6&lt;/h6>
&lt;h2 id="paragraph">Paragraph&lt;/h2>
&lt;p>Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.&lt;/p></description></item><item><title>Shortcodes Samples</title><link>https://deepakbaby.in/posts/shortcodes/</link><pubDate>Thu, 08 Jun 2000 08:06:25 +0600</pubDate><guid>https://deepakbaby.in/posts/shortcodes/</guid><description>&lt;p>This is a sample post intended to test the followings:&lt;/p>
&lt;ul>
&lt;li>Default hero image.&lt;/li>
&lt;li>Different shortcodes.&lt;/li>
&lt;/ul>
&lt;h2 id="alert">Alert&lt;/h2>
&lt;p>The following alerts are available in this theme.&lt;/p>



 


&lt;div class="alert success">
 &lt;span>&lt;i data-feather="check-circle">&lt;/i>&lt;/span>
 &lt;span>&lt;strong>This is sample alert with &lt;code>type=&amp;quot;success&amp;quot;&lt;/code>.&lt;/strong>&lt;/span>
&lt;/div>




 


&lt;div class="alert danger">
 &lt;span>&lt;i data-feather="alert-octagon">&lt;/i>&lt;/span>
 &lt;span>&lt;strong>This is sample alert with &lt;code>type=&amp;quot;danger&amp;quot;&lt;/code>.&lt;/strong>&lt;/span>
&lt;/div>




 


&lt;div class="alert warning">
 &lt;span>&lt;i data-feather="alert-triangle">&lt;/i>&lt;/span>
 &lt;span>&lt;strong>This is sample alert with &lt;code>type=&amp;quot;warning&amp;quot;&lt;/code>.&lt;/strong>&lt;/span>
&lt;/div>




 


&lt;div class="alert info">
 &lt;span>&lt;i data-feather="info">&lt;/i>&lt;/span>
 &lt;span>&lt;strong>This is sample alert with &lt;code>type=&amp;quot;info&amp;quot;&lt;/code>.&lt;/strong>&lt;/span>
&lt;/div>





&lt;div class="alert dark">
 &lt;span>&lt;i data-feather="alert-circle">&lt;/i>&lt;/span>
 &lt;span>&lt;strong>This is sample alert with &lt;code>type=&amp;quot;dark&amp;quot;&lt;/code>.&lt;/strong>&lt;/span>
&lt;/div>





&lt;div class="alert primary">
 &lt;span>&lt;i data-feather="alert-circle">&lt;/i>&lt;/span>
 &lt;span>&lt;strong>This is sample alert with &lt;code>type=&amp;quot;primary&amp;quot;&lt;/code>.&lt;/strong>&lt;/span>
&lt;/div>





&lt;div class="alert secondary">
 &lt;span>&lt;i data-feather="alert-circle">&lt;/i>&lt;/span>
 &lt;span>&lt;strong>This is sample alert with &lt;code>type=&amp;quot;secondary&amp;quot;&lt;/code>.&lt;/strong>&lt;/span>
&lt;/div>

&lt;h2 id="image">Image&lt;/h2>
&lt;h4 id="a-sample-image-without-any-attribute">A sample image without any attribute.&lt;/h4>
&lt;img src="https://deepakbaby.in/posts/shortcodes/boat.jpg"
 
 alt="A boat at the sea"
 
 
 
 
 
>

&lt;div style="margin-top: 3rem;">&lt;/div>
&lt;h4 id="a-sample-image-with-height-and-width-attributes">A sample image with &lt;code>height&lt;/code> and &lt;code>width&lt;/code> attributes.&lt;/h4>
&lt;img src="https://deepakbaby.in/posts/shortcodes/boat.jpg"
 
 alt="A boat at the sea"
 
 
 width="600"
 
 
 height="400"
 
 
 
>

&lt;div style="margin-top: 3rem;">&lt;/div>
&lt;h4 id="a-center-aligned-image-with-height-and-width-attributes">A center aligned image with &lt;code>height&lt;/code> and &lt;code>width&lt;/code> attributes.&lt;/h4>
&lt;img src="https://deepakbaby.in/posts/shortcodes/boat.jpg"
 
 alt="A boat at the sea"
 
 
 width="600"
 
 
 height="400"
 
 
 
 class="center"
 
>

&lt;div style="margin-top: 3rem;">&lt;/div>
&lt;h4 id="a-image-with-float-attribute">A image with &lt;code>float&lt;/code> attribute.&lt;/h4>
&lt;img src="https://deepakbaby.in/posts/shortcodes/boat.jpg"
 
 alt="A boat at the sea"
 
 
 width="500"
 
 
 height="200"
 
 
 style="float: right;"
 
 
>

&lt;p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras egestas lectus sed leo ultricies ultricies. Praesent tellus risus, eleifend vel efficitur ac, venenatis sit amet sem. Ut ut egestas erat. Fusce ut leo turpis. Morbi consectetur sed lacus vitae vehicula. Cras gravida turpis id eleifend volutpat. Suspendisse nec ipsum eu erat finibus dictum. Morbi volutpat nulla purus, vel maximus ex molestie id. Nullam posuere est urna, at fringilla eros venenatis quis.&lt;/p></description></item></channel></rss>