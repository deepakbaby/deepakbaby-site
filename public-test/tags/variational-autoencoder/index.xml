<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Variational Autoencoder on Deepak Baby</title><link>https://deepakbaby.in/tags/variational-autoencoder/</link><description>Recent content in Variational Autoencoder on Deepak Baby</description><generator>Hugo</generator><language>en</language><lastBuildDate>Tue, 02 Jul 2019 16:44:25 +0200</lastBuildDate><atom:link href="https://deepakbaby.in/tags/variational-autoencoder/index.xml" rel="self" type="application/rss+xml"/><item><title>Understanding Variational Autoencoders and Implementation in Keras</title><link>https://deepakbaby.in/posts/vae-keras/</link><pubDate>Tue, 02 Jul 2019 16:44:25 +0200</pubDate><guid>https://deepakbaby.in/posts/vae-keras/</guid><description>&lt;p>Variational Autoencoders (VAEs)&lt;a href="https://arxiv.org/abs/1312.6114">[Kingma, et.al (2013)]&lt;/a> let us design complex generative models of data that can be trained on large datasets. This post is about understanding the VAE concepts, its loss functions and how we can implement it in keras.&lt;/p>
&lt;h2 id="generating-data-from-a-latent-space">Generating data from a latent space&lt;/h2>
&lt;p>VAEs, in terms of probabilistic terms, assume that the data-points in a large dataset are generated from a latent space. For e.g., let us assume we want to generate the image of an animal. First we imagine that it has four legs, a head and a tail. This is analogous to the latent space and from this set of characteristics that are defined in the latent space, the model will learn to generate the image of an animal.&lt;/p></description></item></channel></rss>